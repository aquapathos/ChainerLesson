{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 大きいサイズにチャレンジ\n",
    "分割して処理し，統合してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Fake Painter\n",
    "\n",
    "Fake Painter はどんなサイズの画像でも224x224にリサイズして処理していましたが，もっと大きな絵を描かせてみたいな，という要望に応えてみました．\n",
    "\n",
    "動作環境\n",
    "- Windows, MacOS, Linux で動作確認済み。いずれも Anaconda\n",
    "- chainer 2.0\n",
    "- python3.6 （3.5でもよい）\n",
    "- opencv 3.2 (3.0でもよい。２でもよいかも） PILだけでも書けると思うが、本人が PIL より慣れてるためちょっとだけ使った。 \n",
    "\n",
    "縦も横も200の倍数＋224でもっとも画像サイズに近いサイズに画像をリサイズし，224×224のブロック単位で処理します．\n",
    "単純に分割処理すると境界がくっきりと目立ってしまって連続性がなくなるので，隣のブロックとは24ピクセル分重ねることにしました．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer.functions as F\n",
    "import chainer\n",
    "from chainer.links import VGG16Layers\n",
    "from chainer.links.model.vision.vgg import prepare as VGGprepare\n",
    "from chainer import Variable, optimizers\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from PIL import ImageFilter\n",
    "from io import BytesIO\n",
    "import urllib.request\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "#from IPython.html.widgets import FloatProgress\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import clear_output, Image, display\n",
    "\n",
    "mean = [103.939, 116.779, 123.68]   # BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基本入出力関数\n",
    "\n",
    "# url を指定して画像を読み込み\n",
    "def url2img(url):\n",
    "    url_response = urllib.request.urlopen(url)\n",
    "    img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_array, -1)\n",
    "    img =PIL.Image.fromarray(img[:, :, ::-1].copy())\n",
    "    return img\n",
    "\n",
    "# ファイルまたはウェブ上のファイルを読み込み\n",
    "def getImage(filename):\n",
    "        if filename[:4] == \"http\":\n",
    "            img = url2img(filename)\n",
    "        else:\n",
    "            img = PIL.Image.open(filename)\n",
    "        return img\n",
    "\n",
    "# numpy画像の表示\n",
    "def showarray(a, fmt='jpeg'):  # \n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "# blob データを PIL 画像に変換\n",
    "def blob2img(blob, mean=mean):\n",
    "    blob = (np.dstack(blob)+ mean)[:,:,::-1]   # BGR 2 RGB\n",
    "    return PIL.Image.fromarray(np.uint8(np.clip(blob,0,255)))\n",
    "\n",
    "# blob データを画像として保存\n",
    "def save_image(blobimg, it, fn = \"frames\",mean =mean):\n",
    "    image = blob2img(blobimg, mean=mean)\n",
    "    image.save(fn+\"/im_%05d.png\"%it)\n",
    "    return image\n",
    "\n",
    "# チャネル間の相関行列\n",
    "def ch_corr_matrix(ld):\n",
    "    # 0次元目はバッチ数\n",
    "    ch = ld.shape[1] # チャネル数\n",
    "    size = ld[0][0].size  # チャネルあたりのデータ数\n",
    "    cmatrix = F.reshape(ld, (ch,size)) # チャネルごとに１次元化した ch x size の配列を作る\n",
    "    matrix = F.matmul(cmatrix, cmatrix,transb=True) / np.float32(ch*size) # 相関行列\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# layers_for_orig = [\"conv4_1\", \"conv4_2\", \"conv4_3\", \"pool4\"]\n",
    "# layers_for_style =[\"conv1_1\", \"conv1_2\", \"pool1\", \"conv2_1\", \"conv2_2\", \"pool2\", \"conv3_1\", \"conv3_2\", \"conv3_3v3\",\"pool3\"]\n",
    "\n",
    "CROPSIZE = (3,224,224)\n",
    "\n",
    "# Fake Painter -- VGG16Layer の拡張クラス\n",
    "class FakePainter(VGG16Layers):\n",
    "    def __init__(self):\n",
    "        super(FakePainter, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.autopic = chainer.links.Parameter(self.genpic())\n",
    "            self.opic = np.zeros(CROPSIZE ,dtype='f')\n",
    "            self.spic = np.zeros(CROPSIZE ,dtype='f')\n",
    "    \n",
    "    def __call__(self, vimg, layers=['prob']):\n",
    "         return self.myextract(vimg, layers=layers)\n",
    "            \n",
    "    def myextract(self,vimg, layers=['prob']):\n",
    "        if vimg.data.ndim == 3:\n",
    "            vimg = F.reshape(vimg,(1,3,224,224))\n",
    "        return super(FakePainter,self).__call__(vimg,layers=layers)\n",
    "    \n",
    "    def genpic(self):\n",
    "        genpic = np.random.uniform(-20,20,CROPSIZE ).astype(np.float32)\n",
    "        return genpic\n",
    "    \n",
    "    def setpic(self, nimg):\n",
    "        self.autopic.W.data = nimg\n",
    " \n",
    "    def show(self,mode=0):\n",
    "        if mode == 1 :\n",
    "           img = blob2img(self.opic)\n",
    "        elif mode == 2 :\n",
    "           img = blob2img(self.spic)\n",
    "        else :\n",
    "           img = blob2img(self.autopic.data)  \n",
    "        return img\n",
    "        \n",
    "    # VGGprepare を使って画像をVGG16用に変換\n",
    "    def setImage(self,img, withsmooth=False):\n",
    "        nimg = VGGprepare(img)\n",
    "        if withsmooth:\n",
    "            mag = min(img.size)/224\n",
    "            self.smimg = img.filter(ImageFilter.GaussianBlur(3*mag))# ぼかしたイメージ \n",
    "            nsmimg = VGGprepare(self.smimg)\n",
    "            return nimg, nsmimg\n",
    "        else:\n",
    "            return nimg\n",
    "        \n",
    "    # autopic をもとに前向き伝搬\n",
    "    def autoforward(self,layers=['prob']):\n",
    "        h = self.myextract(self.autopic, layers=layers)\n",
    "        return h\n",
    "    \n",
    "    # 処理対象画像をセット\n",
    "    def setOimage(self,img, layers=['vpool4']):\n",
    "        self.opic, smpic =  self.setImage(img, withsmooth=True)\n",
    "        vimg = Variable(self.opic)\n",
    "        h = self.myextract(vimg,layers=layers)  # 対象画像の特徴情報\n",
    "        self.Ofeatures = h\n",
    "        self.vsmimg = smpic\n",
    "        \n",
    "    # スタイル画像をセット\n",
    "    def setSimage(self,img,layers=['conv4_1']):\n",
    "        self.spic =  self.setImage(img)\n",
    "        vimg = Variable(self.spic)\n",
    "        h = self.myextract(vimg,layers=layers)\n",
    "        cor = {}\n",
    "        for l in h.keys():\n",
    "            cor.update({l:ch_corr_matrix(h[l])})\n",
    "        self.Sfeatures = h\n",
    "        self.Scorr = cor\n",
    "\n",
    "################ \n",
    "nn=FakePainter()    ##  <- これが主役\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本となる 224x224 サイズの画像の描画\n",
    "def generate224(nn,oimg,styleimg,itr,l1,l2,dlosslimit):\n",
    "        global progress2        \n",
    "        nn.setOimage(oimg,l1)\n",
    "        nn.setSimage(styleimg,l2)\n",
    "        \n",
    "        # パラメータ\n",
    "        oldloss = np.array([1e+30,1e+30,1e+30,1e+30]) # \n",
    "        tolerance = 2 # この回数以上 loss が前より上昇したらあきらめる\n",
    "        upcount = 0 # loss が連続上昇した回数のカウンタ\n",
    "\n",
    "        # train mode\n",
    "        chainer.config.train=False\n",
    "        chainer.config.enable_backprop=True\n",
    "\n",
    "        optimizer = optimizers.Adam(alpha=lr, beta1=0.5)\n",
    "        optimizer.setup(nn.autopic)\n",
    "\n",
    "        # oldx = nn.autopic.W  # 　前回の　x の値の初期値     myoptimize を使う場合はこの2行のコメントをはずす\n",
    "        # oldx.grad = np.zeros_like(oldx.data)  # grad はゼロにセット\n",
    "\n",
    "        for times  in range (itr):\n",
    "            nn.cleargrads()  # 微係数データを初期化                \n",
    "            loss = Variable(np.zeros(()).astype(np.float32))\n",
    "            loss1 = Variable(np.zeros(()).astype(np.float32))  # 入力画像との自乗誤差\n",
    "            loss2 = Variable(np.zeros(()).astype(np.float32))  # スタイル画像とのチャネル相関の自乗誤差\n",
    "\n",
    "            #  l1での現画像と入力画像の誤差を求める\n",
    "            x = nn.autopic.W\n",
    "            # 前向き伝搬して指定した層のデータを取得\n",
    "            efs = nn.myextract(x,layers=list(set(l1+l2)))\n",
    "            \n",
    "            for key in l1:\n",
    "                ef = efs[key]\n",
    "                of = nn.Ofeatures[key].data  # 先に保存してある対象画像の指定層データ\n",
    "                loss1 += F.mean_squared_error(ef,of)   # 距離を誤差とする\n",
    " \n",
    "            #  l2での現画像とスタイル画像のチャネル相関誤差を求める\n",
    "            for key in l2:\n",
    "                ef = efs[key]\n",
    "                of = Variable(nn.Sfeatures[key].data) # 先に保存してあるスタイル画像の指定データ\n",
    "                ecm = ch_corr_matrix(ef)   # チャネル相関マトリクス\n",
    "                ocm = nn.Scorr[key].data  # 先に保存してあるスタイル画像のチャネル相関マトリクス\n",
    "                loss2 += F.mean_squared_error(ecm, ocm)  # マトリクス間の自乗誤差\n",
    "\n",
    "            loss3 = F.mean_squared_error(x, Variable(nn.vsmimg))    # 元の画像におおまかに近づけるための項\n",
    "           \n",
    "            loss = rr1*loss1+rr2*loss2+(1-rr1-rr2)*loss3\n",
    "                        \n",
    "            loss.backward()\n",
    "\n",
    "            xgrad = x.grad   #　 loss に対する入力の寄与を保存\n",
    "            nn.cleargrads()  # nn 全体の微分データをクリア\n",
    "            x.grad = xgrad\n",
    "\n",
    "            # chainer のオプティマイザーを使わない場合はこの4行のコメントを外す\n",
    "            # def myoptimize(oldvimg, vimg, alpha=0.1, beta=0.5):\n",
    "            #    vimg.data -= alpha * ( vimg.grad + beta * oldvimg.grad)\n",
    "            # return vimg\n",
    "            # x = myoptimize(oldx, x, alpha = lr, beta = 0.5)\n",
    "\n",
    "            # chainer のオプティマイザー\n",
    "            optimizer.update()\n",
    "           \n",
    "            nn.autopic.W = x   # 自動生成画像を更新データで上書き\n",
    "            \n",
    "            # 0+xxx としているのは，そうしないと formet が型エラーを吐くから\n",
    "            tl, tl1,tl2,tl3 = 0+loss.data, 0+rr1*loss1.data, 0+rr2*loss2.data, 0+(1-rr1-rr2)*loss3.data\n",
    "            if times > 0:\n",
    "                sys.stdout.write(\"\\r{:5d} {:.5f}  = {:.5f} +{:.5f}+ {:.5f}  ( {:.5f}  {:.5f}  {:.5f} ({}))\".format(times, tl, tl1, tl2, tl3, tl1-oldloss[1], tl2-oldloss[2], tl3-oldloss[3],upcount))\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "            progress2.value = times\n",
    "            \n",
    "            # oldx = x    #  1回前の x を記憶  myoptimize を使う場合はコメントを外す\n",
    "            \n",
    "            if   loss.data < dlosslimit:\n",
    "                print(\"評価基準を超えた\")\n",
    "                break\n",
    "            if   loss.data > oldloss[0]:\n",
    "                upcount = upcount + 1\n",
    "            else:\n",
    "                upcount = 0\n",
    "            if upcount > tolerance:\n",
    "                print(\"ロスが増えつづけているので停止\")\n",
    "                break\n",
    "                \n",
    "            oldloss = (tl, tl1,tl2,tl3)   \n",
    " \n",
    "        return blob2img(nn.autopic.W.data,mean=mean),loss.data\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描画メソッド\n",
    "def generate3(nn,oimg,style, steps=1,itr=100,cont=False,l1=['conv4_3','pool4'], \\\n",
    "              l2=['conv4_1','conv4_2','conv4_3','pool4'],\\\n",
    "             fn=\"frames\", dlosslimit = 100):\n",
    "    # nn: ネットワーク、oimg：対象画像名, style：スタイル画像, cont: 前回の続き、\\\n",
    "    # itr:繰り返し回数, l1: oimgから取り出す階層、l2:style から取り出す階層, \n",
    "    # fn: 出力フォルダ名, \n",
    "    # dlossliit: loss がこれ以上下がったら終わる \n",
    "\n",
    "    # 描画対象画像の読み込み\n",
    "    Oimg = PIL.Image.open(oimg)  # 原画像\n",
    "    (width,height) = Oimg.size   # 原画像のサイズ\n",
    "    # スタイル画像をセット\n",
    "    styleimg = getImage(style)\n",
    "\n",
    "    # Progress bar\n",
    "    global progress0,progress1,progress2\n",
    "    progress0 = FloatProgress(min=0, max=steps-1)\n",
    "    progress1 = FloatProgress(min=0, max=(int((width-223)/200)+1)*(int((height-223)/200)+1))    \n",
    "    progress2 = FloatProgress(min=0, max=itr-1)\n",
    "    display(progress0)\n",
    "    display(progress1)\n",
    "    display(progress2)\n",
    "\n",
    "    bimg = Oimg.copy().filter(ImageFilter.GaussianBlur(25))\n",
    "    nn.autopic.W.data = VGGprepare(bimg) # autopic にぼかした画像をセット\n",
    "    \n",
    "    # 画像全体を使って１サイクル描画を実行する．これを拡大分割したものを各ブロックの種とする\n",
    "    Firstimg,_= generate224(nn,Oimg,styleimg,itr=itr,l1=l1, l2=l2, \\\n",
    "                                  dlosslimit=dlosslimit)\n",
    "     \n",
    "    # 200の倍数＋224で画像より小さくかつもっとも画像サイズに近いサイズを計算\n",
    "    width1 = (int((width-224)/200))*200+224 \n",
    "    height1 = (int((height-224)/200))*200+224  \n",
    "    Oimg = Oimg.resize(np.array((width1,height1))) # 原画像のサイズをフィットさせる\n",
    "    # ぼかしのために枠をつける\n",
    "    Bimg = PIL.Image.new('RGB', (width1+50, height1+50), (200, 200, 200)) \n",
    "    mX, mY = 25,25 \n",
    "    Bimg.paste(Firstimg.resize(Oimg.size),(mX,mY))  # キャンバスの中央に原画像を配置\n",
    "    canvas = Bimg.copy()  \n",
    "    showarray(canvas.resize(np.array(canvas.size)//2))\n",
    "    canvas.save(fn+\"/qimg_00000.png\")     \n",
    "\n",
    "    oldtotalloss = 1e+30\n",
    "    for step in range(steps):\n",
    "        progress0.value=step\n",
    "        pgc = 0\n",
    "        totalloss = 0\n",
    "        for h in range(0,height1-223,200):\n",
    "            for w in range(0,width1-223,200):\n",
    "                pgc=pgc+1 # プログレスバーのカウンター\n",
    "                progress1.value = pgc\n",
    "                \n",
    "                qimg = canvas.crop((w+mX,h+mY,w+mX+224,h+mY+224))  # Qimgを初期値に使う                \n",
    "                qimgVGG = VGGprepare(qimg)\n",
    "                nn.setpic(qimgVGG)\n",
    "                \n",
    "                img = Oimg.crop((w,h,w+224,h+224))\n",
    "                \n",
    "                rimg,aloss = generate224(nn,img,styleimg,itr=itr,l1=l1, l2=l2, \\\n",
    "                                  dlosslimit=dlosslimit)\n",
    "\n",
    "                canvas.paste(rimg, (w+mX,h+mY))\n",
    "                \n",
    "                totalloss = totalloss + aloss\n",
    "        \n",
    "        showarray(canvas.resize(np.array(canvas.size)//2))\n",
    "        canvas.save(fn+\"/all_%05d.png\"%step)\n",
    "\n",
    "        if totalloss > oldtotalloss:\n",
    "            printf(\"Total loss が増えすぎているので停止\")\n",
    "            break\n",
    "        \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験用画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(\"images/momiji.jpg\")\n",
    "img.resize(np.array(img.size)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(\"images/Mucha.png\")\n",
    "img.resize(np.array(img.size)//1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(\"images/kusama.png\")\n",
    "img.resize(np.array(img.size)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msurl =  'https://goo.gl/ZCnjHJ'\n",
    "img = url2img(msurl)\n",
    "img.resize(np.array(img.size)//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ex0\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.00)\n",
    "rr2 = np.float32(0.00)\n",
    "generate3(nn,\"images/momiji.jpg\",\"images/Mucha.png\",steps=2,itr=3, fn=\"ex0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ex0\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.02)\n",
    "generate3(nn,\"images/momiji.jpg\",\"images/Mucha.png\",steps=2,itr=3, fn=\"ex0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まず基本\n",
    "参照原画に似せる項のみ。当然ながらただちに原画そのものになる。ボケてるのは、ぼかして使っているから。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex8\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.0)\n",
    "img = generate3(nn,\"images/momiji.jpg\",\"images/Mucha.png\",steps=5,itr=5, fn=\"ex8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex8\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.0)\n",
    "img = generate3(nn,\"images/momiji.jpg\",\"images/Mucha.png\",steps=5,itr=5, fn=\"ex8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex8\n",
    "lr = np.float32(1.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.0)\n",
    "img = generate3(nn,\"images/momiji.jpg\",\"images/kusama.png\",steps=5,itr=5, fn=\"ex10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex8\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.5)\n",
    "img = generate3(nn,\"images/momiji.jpg\",\"images/kusama.png\",steps=5,itr=5, fn=\"ex10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex12\n",
    "lr = np.float32(3.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.5)\n",
    "img = generate3(nn,\"images/momiji.jpg\",\"images/mstyle.png\",steps=20,itr=5, fn=\"ex12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex13\n",
    "lr = np.float32(1.0) # 学習係数\n",
    "rr1 = np.float32(0.05)\n",
    "rr2 = np.float32(0.15)\n",
    "rr3 = np.float32(0.2)\n",
    "img = generate3(nn,\"images/momiji.jpg\",\"images/mstyle.png\",steps=20,itr=5, fn=\"ex13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ex12\n",
    "lr = np.float32(2000.0) # 学習係数\n",
    "rr1 = np.float32(0.02)\n",
    "rr2 = np.float32(0.03)\n",
    "generate(nn,\"images/himawari.png\",msurl,crop=3,itr=50, fn=\"ex12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!convert -delay 12 -loop 0 -resize 300x tes/*.png tes.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つなぎ目が目立たないようにするために，単純に224ｘ224で区切るのではなく，隣接するブロック同士に重なりのエリアを設け，重なり部分は先行して処理したブロックの処理結果で固定化することにする．\n",
    "\n",
    "### 実験\n",
    "\n",
    "重なりを24ピクセルとして試してみる．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!mkdir ex4\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.00)\n",
    "rr2 = np.float32(1)\n",
    "generate(nn,\"images/himawari.png\",msurl,itr=30, fn=\"ex4\", interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex12\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "generate2(nn,\"images/Quebec.jpg\",\"images/Mucha.png\",tlsteps=5,itr=5, fn=\"ex12\",interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !mkdir ex13\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.01)\n",
    "generate2(nn,\"images/Quebec.jpg\",\"images/Mucha.png\",tlsteps=5,itr=5, fn=\"ex13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex14\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.01)\n",
    "generate2(nn,\"images/Quebec.jpg\",\"images/Mucha.png\",tlsteps=5,itr=5, fn=\"ex14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!mkdir ex16\n",
    "lr = np.float32(10.0) # 学習係数\n",
    "rr1 = np.float32(0.01)\n",
    "rr2 = np.float32(0.05)\n",
    "rr3 = np.float32(0.5)\n",
    "generate2(nn,\"images/Quebec.jpg\",\"images/Mucha.png\",tlsteps=5,itr=5, fn=\"ex16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,steps=1,0\n",
    "topkeep=True if h > 0 and steps == 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topkeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
